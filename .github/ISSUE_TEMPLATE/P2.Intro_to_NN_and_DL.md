---
name: Phase02-Introduction To Neural Networks and Deep Learning
about: Introduction To Neural Networks and Deep Learning
title: Phase02-Introduction To Neural Networks and Deep Learning
labels: ''
assignees: ''

---

- [x] Section 1: Scaler, vector, matrix, tensor
  - [x] An example of a 3d tensor
  - [ ] how can neural networks deal with scaler, vector, matrix and tensor?
- [x] Section 2: PyTorch Basics
  - [x] Install Pytorch
  - [ ] Pytorch basics video 1-12
- [x] Section 3: Perceptron (Feed Forward) NN 
  - [x] Single perceptron
  - [x] Multi-layer perceptron (MLP)
- [x] Section 4: Learning Algorithms
  - [x] How does gradient descent algorithm work for Single perceptron?
  - [x] How does gradient descent algorithm work Multi-layer perceptron?
- [x] Section 5: Deep NN
  - [x] How does a neural network become deep?
  - [x] Why deeper NNs are more powerful? [ Multiple layers are much better at generalizing because they learn all the intermediate features between the raw data and the high-level classification]
- [x] Section 5: Datasets and NNs
  - [x] [Fill this section and determine how did you preprocess Housing dataset?][first we should load and open the data file.it is the format of string.first i split the numbers in a row by the tab space between them then i add them to a numpy array and split it to 2 sets of train set and test set then convert them to tensor. and we can do another work and that is feature scalling and scale the datas to numbers in range(-3,3) ]
  - [x] [Fill this section and determine how did you apply Housing dataset to NN?][I create a neural network with input layer with 13 features one hddden layer with 512 perceptrons and one output layer with one output perceptron with  RELU activation function and train that with learning rate=0.01 and loss=crossentropy and batch_size=16 ]
  - [x] [Fill this section and determine how did you preprocess MNIST dataset?][It is better to use CNN to have better accuracy and less complexity in this case we should convolve each data with specific filter the max pool them to reduce the size and then flat the 2d array then we send that to the ANN.]
  - [ ]
  - [x] [Fill this section and determine how did you apply MNIST dataset to NN?][ As i said in previous question  first we flatten the 2d input and send it to ANN. And this ANN has 4 hidden layers each of them has perceptrons in the order of 500 perceptrons and in the end we have a 10 perceptrons output and each of them is the probability of each digit ]
